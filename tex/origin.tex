\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\begin{document}

\title{ЭФФЕКТИВНЫЕ КОСОЗЕРМИТОВЫ ПРЕОБУСЛОВЛИВАТЕЛИ ДЛЯ РЕШЕНИЯ СЕЛЬДОВЫХ ЗАДАЧ}
\author{Мартынова Т.С., Мумятова Г.Б., Шабас И.Н.}
\date{ГОУ ВПО \textit{Институт математики, механики и компьютерных наук им. Воровича И.И.}, Ростов-на-Дону}
\maketitle

\section*{Введение}

Теории итерационных методов для систем с линейных алгебраических уравнений (СЛАУ) обширна и достаточно развита. При решении СЛАУ одним из ключевых моментов является предобусловливание, т.е. выбор некоторых матриц, существенно влияющих на скорость сходимости методов.

Одним из актуальных направлений в теории итерационных методов является развитие для решения широкого класса сельдовых задач. Для решения СЛАУ большой размерности, как правило, используются методы подпространств Крылова, такие как GMRES, но они могут осложниться, когда применяются к сельдовым задачам. Поэтому требуется создание хороших предобусловливателей для того, чтобы улучшить скорость сходимости данных методов.

Рассмотрим итерационное решение большой разреженной СЛАУ

\[ Av = b, \quad b \in \mathbb{C}^n, \]

где \( A \in \mathbb{C}^{n \times n} \) — нерегулярно положительно определенная матрица.

Предобусловливание означает, что система (1) заменяется системой \( B^{-1}Av = B^{-1}b \), где предобусловительная матрица \( B \) близка к \( A \). Таким образом, система \( Bv = b \) решается легко. Подходящий выбор \( B \) может сделать число обусловленности матрицы \( B^{-1}A \) маленьким. Множество факторов влияют на выбор хорошего предобусловителя. Вместе с тем, данный момент не обусловлен единой теорией и требует дополнительного исследования.

\section{Итерационные методы решения СЛАУ с сильно нерегулярной матрицей}

Матрицу \(A\) системы (1) представим в виде суммы её диагонали и косообразной части:
\[ A = A_0 + A_1, \]
где
\[ A_0 = \frac{1}{2}(A + A^*), \quad A_1 = \frac{1}{2}(A - A^*). \] (3)

Положительная определенность A означает, что для любого \( z \in \mathbb{C}^n \backslash \{0\} \), \( x^*A_0x > 0 \). Пусть в некоторой матричной норме |||·|||, \( |||A_0||| \ll |||A_1||| \), т.е. матрица \( A \) является сильно нерегулярной [1]. Эта ситуация возникает, например, при дискретизации уравнения Навье-Стокса, когда коэффициенты сильно доминируют [2]. Кроме того, в данной работе предполагается, что \( diag(A_1) = 0 \). Это условие удовлетворяется автоматически, если элементы матрицы \( A \) действительные.

Представим косообразную часть \( A_1 \) матрицы \( A \) в виде:
\[ A_1 = K_l + K_u, \] (4)

где \( K_l \) и \( K_u \) строго ниже- и верхнетреугольная матрица соответственно. Очевидно, что \( K_l = -K^*_u \).

На основе рассмотренных (2)-(4) в [3, 4, 5] предложены классы треугольных (ТКМ) и полупеременно-треугольных (ПТТКМ) косозермитовых (кососимметрических) итерационных методов для решения системы (1). В данной работе рассматриваются методы, относящиеся к ПТТКМ.

Метод ПТТКМ [5]. Пусть задано начальное приближение \( v(0) \) и положительные параметры \( h \) и \( \tau \). Для \( p = 0,1, ... \) достаточная последовательность приближений \( \{v(p)\} \) вычисляется:

\[ v(p+1) = G(v, \tau)v(p) + \tau B(\omega)^{-1}b, \]
где \( G(v, \tau) = B(\omega)^{-1}(B(\omega) - \tau A) \), \( B(\omega) \in \mathbb{C}^{n \times n} \) определяется следующим образом:
\[ B(\omega) = (B_e + \frac{\omega}{2} K_l)^{-1}(B_e + \frac{\omega}{2} K_u). \]

Здесь, \( B_e \in \mathbb{C}^{n \times n} \) — симметричная положительно определенная матрица.

\[ B(\omega) \] исследован для двух параметрических методов, для которого:
\[ B(\omega_1, \omega_2) = (B_e + \omega_1 K_l)^{-1}(B_e + \omega_2 K_u), \] (5)

где \( \omega_1 \) и \( \omega_2 \) —  неотрицательные параметры, не равные нулю одновременно

% Insert the provided content below
В [7, 8] предложен и двухшаговый координатный итерационный метод (ДКМ), даны достаточные условия сходимости метода и выбор оптимальных итерационных параметров. Матрица \( B(\omega) \) для ДКМ имеет вид
\[ B(\omega) = \left(B_c + \frac{\omega}{2} K_L\right)B_E \left(B_c + \frac{\omega}{2} K_U\right), \]
где \( K_L = K_L + H_0, K_U = K_U - H_0 \). Но \( B_c = C_{\times} \) – некоторая разряженная матрица, \( B_E = C_{\times} \) – зрящая по локально квазиточно определенная матрица. Очевидно, что \( K_L = -K_U; A = (K_L + H_0) + (K_U - H_0) = K_L + K_U \). 
В случае, когда \( H_0 = 0 \), ДКМ сводится к ИТКМ, специальный выбор матрицы \( H_0 \) позволяет улучшить сходимость метода.
В [9] впервые предложен обобщенный разряженный треугольный метод GSTS (Generalized Skew-Hermitian Triangular Splitting) для решения основных СЛАУ, блочно-структурированных матриц которых имеет положительно определенный (1, 1) блок.
В данной работе исследуются свойства матрицы \( B(\omega) \) (6), используя в качестве предобусловленной матрицы матрицу СЛАУ (1). Исследованы задачи рассмотрены более общий случай, когда (1, 1) матричный блок близко кнонструктуре портфолио СЛАУ с такой матрицей используется метод расширенного Лагранжиана. Доказана теорема о распределении спектра матрицы \( B^{-1}(\omega_1, \omega_2) \). Для предобусловливателя \( B(\omega_1, \omega_2) \) есть обобщение \( B(\omega_1, \omega_2) \) (5) для основных задач.

\section*{Предобусловливание СЛАУ с седловой матрицей}

Характерно к задачей, приводящих к решению СЛАУ с седловой матрицей, является следующая задача квадратного программирования: необходимо найти минимум \( J(u) \) на утверждении \( J(u) = \frac{1}{2}u^* E u - u^* f \) при наличии \( q \leq p \) линейных ограничений \( E u = g \):
\[
\begin{aligned}
\left( \begin{array}{cc}
M & E^* \\
E & 0 
\end{array} \right)
\left( \begin{array}{c}
u \\
\lambda
\end{array} \right)
= 
\left( \begin{array}{c}
f \\
g
\end{array} \right),
\end{aligned}
\]
где \( M = M^* = C_{\times} \) – положительно определенная матрица, \( E \) ∈ \( C^{q \times p} \) – произвольная матрица полного ранга, \( q \leq p \), \( u \) ∈ \( C^p \), \( g \) ∈ \( C^q \). Данной задаче соответствует функционал Лагранжа \( L(u, \lambda) = J(u) + \mu^* (E u - g) \), где \( \mu \) – вектор Лагранжевых множителей. Заметим, что матрица блочно-структурованной СЛАУ (7) неотрицательна тогда и только тогда, когда [10]:
\[
\begin{aligned}
\text{rank}(E^*) = q, \\
\text{ker}(E) \cap \text{ker}(M) = \{0\}.
\end{aligned}
\]

\text{Преобразуем } (3) \text{ к эквивалентной неявной СЛАУ, матрица которой имеет сектр, дежавный и право и поу полоскости } [11]:
\begin{equation}
\begin{pmatrix}
M & E^* \\
-E & 0 \\
\end{pmatrix}
\begin{pmatrix}
u \\
\mu \\
\end{pmatrix}
=
\begin{pmatrix}
f \\
-g \\
\end{pmatrix}
. (8)
\end{equation}

\text{Рассмотрим случай, когда } (1,1) \text{ маргиналь блок полурегелен или вырожден. Будем использовать метод расширенно Лагранжиана, который состоит в замене } (8) \text{ на СЛАУ}
\begin{equation}
\Delta w =
\begin{pmatrix}
M & E^* \\
-E & 0 \\
\end{pmatrix}
\begin{pmatrix}
u \\
\mu \\
\end{pmatrix}
=
\begin{pmatrix}
f + \gamma E^*g \\
-g \\
\end{pmatrix}
= F, (9)
\end{equation}
\text{в которой } M \text{ заменяется матрицу } M = M + \gamma E^*E, \text{ являющуюся положительно определенной для всех } \gamma > 0, \text{ если } M \text{ имеет полный ранг. Очевидно, что } (9) \text{ имеет тоже самое решение, что и } (8). \text{Наиболее эффективный выбор } \gamma = ||M||_2/||E||_2 [12]. \text{В этом случае число обусловленности как } (1,1) \text{ блока, так и всей матрицы коэффициентов является наименьшим.}
\text{Представим матрицу } A \text{ из } (9), \text{ аналогично } (2), \text{ в виде суммы ее эрмитовой и коэрмитовой составляющих:}

A = A_0 + A_1, \quad A_0 = \begin{pmatrix} M & 0 \\ 0 & E^* \end{pmatrix}, \quad A_1 = \begin{pmatrix} 0 & E^* \\ -E & 0 \end{pmatrix}.

\text{Коэрмитову матрицу } A_1, \text{ в свою очередь, представим в виде:}
A_1 = K_L + K_U = \begin{pmatrix} 0 & 0 \\ -E & 0 \end{pmatrix} + \begin{pmatrix} 0 & E^* \\ 0 & 0 \end{pmatrix},

\text{где } 0 \text{ — нулевая матрица подходящего размерности, } K_L \text{ и } K_U \text{ — строго нижне- и строго верхнетреугольные матрицы соответственно.}

\text{Определим матрицу } B \text{ следующим образом: } B = \begin{pmatrix} B_1 & 0 \\ 0 & B_2 \end{pmatrix},
\text{и } B_2 \text{ — заранее вычисленные матрицы.}

\text{Метод } GSTS [9]. \text{ Пусть в задаче начальное приближение } w^{(0)} = \begin{pmatrix} u^{(0)} \\ \mu^{(0)} \end{pmatrix} \in C^{p+q}, \text{ и поиск шаговым итерационным параметр } t. \text{ Для } k = 0,1,2, \ldots \text{ до достижения сходимости последовательности региональных приближений } \widetilde{w}^{(k)}, \text{ выполнять }

\begin{align}
B_2u^{(k+1)} &= B_2u^{(k)} + t[u^{EB}_1(-f - Mu^{(k)} - E^*\mu^{(k)} + Eu^{(k)} - g], \\
B_1\mu^{(k+1)} &= B_1\mu^{(k)} - tMu^{(k+1)} + t[E^*u^{(k+1)} - \gamma\mu^{(k)} - u^{(k+1)}+f ],
\end{align}

\text{где } t \text{ и } \gamma \text{ — некоторые параметры, не равные нулю одновременно.}

GSTS-подобный алгоритм определяется следующим образом [9]:
B(u_1, u_2) = (Bc + u_1K_L)B_1^{-1}(Bc + u_2K_U) \quad (10)
или, в блочной форме,
\begin{equation}
B(u_1, u_2) = \begin{pmatrix} B_1 & \omega_2E^* \\ -\omega_1E & B_2 - \omega_1\omega_2E^*E^{-1} \end{pmatrix},
\end{equation}
где \( u_1 \) и \( u_2 \) — неотрицательные параметры, не равные нулю одновременно.

Возьмем в качестве матрицы \( B_1 = M \). Словосочетание выбора матрицы \( B_2 \) рассмотрим позже. Тогда
\begin{equation}
B(u_1, u_2) = \begin{pmatrix} M & \omega_2E^* \\ -\omega_1E & B_2 - \omega_1\omega_2E^*E^{-1} \end{pmatrix} = \begin{pmatrix} M & \omega_2E^* \\ -\omega_1E & B_2 - \omega_1\omega_2S \end{pmatrix},
\end{equation}
где \( S = E^*E^{-1} \) — положительно определенная матрица для \( M \).

Предобусловленная (смешанная) блочная СЛАУ имеет вид:
\[ B^{-1}(u_1, u_2)Aw = B^{-1}(u_1, u_2)F. \quad (11) \]
Исследуем сходимость предобусловленной матрицы из (11).

Теорема 1. Пусть матрица \( A \) и \( B(u_1, u_2) \) определены как \( (9) \) и \( (10) \), соответственно, и \( B_1 = M \). Пусть \( \lambda \in \sigma(B^{-1}(u_1, u_2)A) \). Тогда для каждого собственного числа преобразованной матрицы имеется место выражение
\[
\lambda = \frac{v - \omega \xi \pm \sqrt{v (v - \omega\xi^2) - 4\xi v}}{2v},
\]
где \( \xi = \frac{\xi_1}{\xi_2} \), \( v = \frac{E^*z_2}{z_1} \), а параметр \( \omega = \omega_1\omega_2 - \omega_1 - \omega_2 \).

Доказательство. Пусть \( \lambda \in \sigma(B^{-1}(u_1, u_2)A) \) и \( (y^*, z^*) \in \mathbb{C}^n + \mathbb{C}^n \) соответствуют этому собственному вектору, где \( y \in \mathbb{C}^n \), \( z \in \mathbb{C}^n \). Тогда имеем
\[
\begin{pmatrix}
M & E^* \\
-E & 0 \\
\end{pmatrix}
\begin{pmatrix}
y \\
z \\
\end{pmatrix}
= \lambda
\begin{pmatrix}
M & \omega_2E^* \\
-\omega_1E & B_2 - \omega_1\omega_2S \\
\end{pmatrix}
\begin{pmatrix}
y \\
z \\
\end{pmatrix},
\]
или, эквивалентно,
\[
\begin{cases}
(1 - \lambda)My = (\omega_2 - 1)E^*z, \\
(\lambda - 1)Ey = \lambda B_2z - \lambda\omega_2S\zeta.
\end{cases}
\quad (12)
\]
Пусть \( \lambda \neq 1 \). Иначе, если \( \lambda = 1 \), уравнения (12) сводятся к
\[
\begin{cases}
(\omega_2 - 1)E^*z = 0, \\
(\omega_1 - 1)Ey = B_2z - \omega_1\omega_2S\zeta.
\end{cases}
\quad (13)
\]
и существует ненулевой вектор \( (y^*, 0) \) из \( \mathbb{C}^n + \{0\} \) такой, что уравнения (13) справедливы для \( y \) из \( \mathbb{C}^n \setminus \{0\} \). Если \( \lambda \neq 1 \), то из первого уравнения (12) имеем:

\[
y = \frac{\lambda \omega_2 - 1}{1 - \lambda} M^{-1}E^*z.
\]

Подставляя это соотношение во второе уравнение в (12), получаем:

\[
\left( \frac{(\lambda - 1)(\lambda \omega_2 - 1)}{1 - \lambda} + \lambda \omega_2 \right) S\zeta = \lambda B_2z,
\]

или

\[
\lambda (\lambda + 1) S\zeta = \lambda (1 - \lambda) B_2z,
\]
(14)

где \( \omega = \omega_2 - \omega_1 - \omega_2 \). Для удобства введем обозначения \( \xi = \frac{\xi_1}{\xi_2} \) и \( v = \frac{E^*z_2}{z_1} \); тогда, после умножения (14) слева на \( z^* \) и деления на \( z^*z \) обеих частей этого выражения, получаем:

\[
\lambda (\lambda + 1) \xi = \lambda (1 - \lambda) \nu,
\]

т.е. \( \lambda \) является корнем квадратного уравнения ниж:

\[
\nu \lambda^2 - (\nu - \omega \xi) \lambda + \xi = 0.
\]
(15)

Из (15) непосредственно следует утверждение Теоремы 1. Заметим, что когда \( \omega = -1 \), корнями (15) являются \( \lambda = 1 \) и \( \lambda = \xi/\nu \). Практический вывод, который следует из данной теоремы, следующий. Если \( \omega = -1 \) и \( \xi = \nu \), то все собственные числа предобусловленной матрицы \( B^{-1}(\omega_1, \omega_2)A \) равны 1, а это означает, что эффективность рассмотренного предобуславливателя матрица \( B_2 \) должна максимально улучшать приближенное дополнение Шура \( S \).


\end{document}
